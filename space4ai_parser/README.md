# SPACE4AI-Parser

The SPACE4AI Parser is designed to convert the YAML file describing the 
candidate components of an AI application and the candidate resources where 
they can be executed into the JSON files processed by 
[SPACE4AI-D](https://gitlab.polimi.it/ai-sprint/space4ai-d) and the 
[SPACE4AI-R Optimizer](https://gitlab.polimi.it/ai-sprint/space4ai-r-optimizer).

Specifically, the input JSON files for S4AI-D/R are generated through a 
`ParserYamlToJson` object, while the production deployment YAML file is 
generated through a `ParserJsonToYaml` object.

Both need to be initialized by specifying:
* `application_dir` (required): the path to the application directory, whose 
expected structure is detailed in 
[the following](#application-directory-structure)
* `who` (required): who is calling the parser, i.e., `s4ai-d` or `s4ai-r`
* `alternative_deployment` (required if SPACE4AI-R is generating its input 
files in a scenario where components with degraded performance are 
considered): the name of the alternative deployment that should be considered 
instead of the one with maximum accuracy level
* `log` (optional): an object of type `Logger`

## Installation

After cloning the current directory, the docker image for the SPACE4AI Parser 
can be generated as follows:

```
IMG_NAME=aisprint/space4ai-parser
IMG_TAG=23.06.30
docker build -t ${IMG_NAME}:${IMG_TAG} .
```

The parser is installed in the `/space4ai-parser` directory. To start the 
docker container in interactive mode, run:

```
CONT_NAME=parser
docker run  -it \
            --rm \
            --name ${CONT_NAME} \
            -v ${PATH_TO_VOLUME}:/mnt \
            ${IMG_NAME}:${IMG_TAG}
```

where `PATH_TO_VOLUME` is the (global) path to the volume where the 
application directory is stored.

The default image `CMD` is related to the test script described in 
[the following](#example).

### Application directory structure

The application directory specified in `application_dir` is assumed to have 
the following structure:

```
.
├── aisprint
│   ├── deployments
│   │   ├── base
│   │   ├── deployment1
│   │   ├── deployment2
│   │   ├── ...
│   │   ├── multi_cluster_qos_constraints.yaml
│   │   └── optimal_deployment
│   ├── designs
│   │   ├── component_partitions.yaml
│   │   ├── < component 1 >
│   │   ├── < component 2 >
│   │   └── ...
│   └── logs
├── ams
├── common_config
│   ├── annotations.yaml
│   ├── application_dag.yaml
│   ├── candidate_deployments.yaml
│   ├── candidate_resources.yaml
├── im
├── oscar
├── oscarp
│   ├── components_data_size.yaml
│   ├── deployment_<deployment index>
│   ├── deployments_summary.txt
│   └── performance_models.json
├── pycompss
├── space4ai-d
│   ├── SPACE4AI-D.yaml
│   └── qos_constraints.yaml
├── space4ai-r
└── src
    ├── <component 1 source code>
    ├── <component 2 source code>
    └── ...
```

The subfolders in `aisprint` as well as some input YAML files in 
`common_config` and `space4ai-d` are generated by running 
[AI-SPRINT Design](https://gitlab.polimi.it/ai-sprint/ai-sprint-studio), 
while the content of the `oscarp` directory is generated by running 
[OSCAR-P](https://gitlab.polimi.it/ai-sprint/OSCAR-P).

Some examples of application directories are provided in 
[AI-SPRINT Examples](https://gitlab.polimi.it/ai-sprint/ai-sprint-examples).

### Running the parser

A script to test the SPACE4AI Parser is provided in 
[test_parser.py](test_parser.py). It is used as follows:

```
usage: test_parser.py [-h] 
                [--test {s4aid_input,s4aid_output,s4air_input,s4air_output}] 
                [--application_dir APPLICATION_DIR]
                [--alternative_deployment ALTERNATIVE_DEPLOYMENT] 
                [--only_edge] 
                [--verbosity_level VERBOSITY_LEVEL]

Testing the SPACE4AI Parser

optional arguments:
  -h, --help            show this help message and exit
  --test {s4aid_input,s4aid_output,s4air_input,s4air_output}
                        Keyword identifying the test to be performed
  --application_dir APPLICATION_DIR
                        Name of the application directory
  --alternative_deployment ALTERNATIVE_DEPLOYMENT
                        Name of the alternative deployment with degraded performance
  --only_edge           True if only edge resources should be considered
  --verbosity_level VERBOSITY_LEVEL
                        Verbosity level for logging
```

According to the value of the `test` parameter, it can be used to test the 
generation of:
* the SPACE4AI-D input files, i.e., the `space4ai-d/SystemFile.json` file with 
the system description and the `space4ai-d/Input.json` file with the 
algorithms parameters
* the `aisprint/deployments/optimal_deployment/production_deployment.yaml` 
file starting from the SPACE4AI-D output json file
* the SPACE4AI-R input files, i.e., the `space4ai-r/SystemFile.json` file with 
the system description, the `space4ai-r/CurrentSolution.json` file taken from 
the `aisprint/deployments/current_deployment/production_deployment.yaml`, and 
the `space4ai-r/Config.json` with the algorithms parameters
* the `aisprint/deployments/optimal_deployment/production_deployment.yaml` 
file starting from the SPACE4AI-R output json file

For instance, the SPACE4AI-D input can be generated by: 
* downloading a sample application directory following the instructions in 
the [README.md](example_applications/README.md) file.
* running:
```
CONT_NAME=parser
PATH_TO_VOLUME=${PWD}/example_applications
TEST_NAME=s4aid_input
APPLICATION_DIR=mask_detection_1_partitionable_local_constraints/step_4
docker run  --name ${CONT_NAME} \
            --rm \
            -v ${PATH_TO_VOLUME}:/mnt \
            ${IMG_NAME}:${IMG_TAG} \
            python3 test_parser.py  \
            --test ${TEST_NAME} \
            --application_dir /mnt/${APPLICATION_DIR}
```

where the `mask_detection_1_partitionable_local_constraints/step_4` directory 
has the structure reported 
[here](https://gitlab.polimi.it/ai-sprint/ai-sprint-examples/-/tree/main/mask_detection_1_partitionable_local_constraints/step_4).

#### Note on alternative deployments

The `alternative_deployment` parameter denotes the name of an 
alternative deployment with degraded performance to be considered. The list 
of available alternatives is provided in 
`space4ai-r/deployments_performance.yaml`, as exemplified 
[here](https://gitlab.polimi.it/ai-sprint/ai-sprint-examples/-/tree/main/filter_classifier_degraded_performance/step_2).

When generating the input files for SPACE4AI-D in the case of degraded 
performance, **an optimal production_deployment.yaml file must be available 
before calling the parser asking for an alternative deployment**. The intended 
pipeline is:
1. generate the SPACE4AI-D input files as exemplified above, without 
specifying any alternative deployment (the original - non degraded - 
deployment will be considered)
2. run SPACE4AI-D to determine the optimal solution
3. convert the SPACE4AI-D `Output.json` into the optimal production deployment 
yaml file
4. generate alternative SPACE4AI-D input files providing to the 
`alternative_deployment` parameter a value taken from the available list. 

Considering as an example the folder 
[`filter_classifier_degraded_performance`](https://gitlab.polimi.it/ai-sprint/ai-sprint-examples/-/tree/main/filter_classifier_degraded_performance/step_4),
step 4 can be executed by running:

```
CONT_NAME=parser
PATH_TO_VOLUME=${PWD}/example_applications
TEST_NAME=s4aid_input
APPLICATION_DIR=filter_classifier_degraded_performance/step_4
docker run  --name ${CONT_NAME} \
            --rm \
            -v ${PATH_TO_VOLUME}:/mnt \
            ${IMG_NAME}:${IMG_TAG} \
            python3 test_parser.py  \
            --test ${TEST_NAME} \
            --application_dir /mnt/${APPLICATION_DIR} \
            --alternative_deployment alternative_deployment1
```

#### Note on only-edge scenarios

The `only_edge` parameter denotes a scenario when only the candidate edge 
resources should be considered. The parser extracts from the input yaml files 
only the edge resources and the components/component partitions that can be 
executed on them. Candidate components or component partitions that are not 
compatible with edge resources are excluded from the generated system.

This scenario is intended to be used **at runtime only**, thus the parameter 
has no effect in producing the input/output for SPACE4AI-D.

Considering as an example the folder 
[`mask_detection_5_three_components`](https://gitlab.polimi.it/ai-sprint/ai-sprint-examples/-/tree/main/mask_detection_5_three_components/step_5),
the only-edge scenario can be tested by running:

```
CONT_NAME=parser
PATH_TO_VOLUME=${PWD}/example_applications
TEST_NAME=s4air_input
APPLICATION_DIR=mask_detection_5_three_components/step_5
docker run  --name ${CONT_NAME} \
            --rm \
            -v ${PATH_TO_VOLUME}:/mnt \
            ${IMG_NAME}:${IMG_TAG} \
            python3 test_parser.py  \
            --test ${TEST_NAME} \
            --application_dir /mnt/${APPLICATION_DIR} \
            --only_edge
```

A warning is printed if some components are left without compatible resources 
in this setting. In the considered example, e.g., we observe:

```
WARNING: No candidate resources for component c3
```

and component `c3` is excluded from the generated system description file.

Note that, if no candidate edge resources are available, the parser prints a 
warning message:

```
WARNING: No candidate resources; the system cannot be optimized
```

and the generated system json file stores empty dictionaries:

```
{
    "Components": {},
    "CompatibilityMatrix": {},
    "Performance": {},
    "NetworkTechnology": {},
    "LocalConstraints": {},
    "GlobalConstraints": {},
    "DirectedAcyclicGraph": {},
    "Lambda": {},
    "Time": {}
}
```

This can be observed when testing, for instance, the only-edge scenario 
considering as application directory the 
[`mask_detection_1_partitionable_local_constraints/step_5`](https://gitlab.polimi.it/ai-sprint/ai-sprint-examples/-/tree/main/mask_detection_1_partitionable_local_constraints/step_5),
where only cloud resources are considered as candidate.
